{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5: Simple Chemical Enviroment - Learning Chemical Reactivity\n",
    "\n",
    "### Due: Friday April 9, 2021\n",
    "\n",
    "### Name: \n",
    "\n",
    "## Part 1 - Exploring the GitHub Code for the Assignment\n",
    "\n",
    "The code for this assignment is located at the [following GitHub repository](https://github.com/chopralab/mop_reactivity_analysis) and you can clone this repository over to your account on scholar using the following command:\n",
    "\n",
    "```\n",
    "git clone https://github.com/chopralab/mop_reactivity_analysis.git\n",
    "```\n",
    "\n",
    "Aftering cloning the repository over to scholar, you can now navigate into the project directory (using `cd` or through VS Code) and see all of the files present that you have to work with (these can also be view on the GitHub repository but you cannot run the scripts here). There are two directories present in the projects base directory `ml` (machine learning) and `qm` (quantum mechanics). For this assignment, we will not use any of the scripts in the `qm` directory but you are welcome to explore the code on your own. Head over to the `ml` directory of the assignment and take a look at what subdirectories are present.\n",
    "\n",
    "### Analytes Subdirectoy\n",
    "\n",
    "This directory contains 3 **SMILES** `(.smi)` files:\n",
    "\n",
    "- `first36.smi` - The original 36 reactions used to train all models\n",
    "    \n",
    "- `test_set_14.smi` - The 14 test reactions\n",
    "    \n",
    "- `full_training_set_smi` - A concatenation of the above two files\n",
    "\n",
    "Each line of a `.smi` file contains a SMILES string representation of a compound (or reaction) and additional information (such as chemical properties) about that compound. When parsing a .smi file, you will have to tell the parser which column corresponds to which chemical property. In the `.smi` files located in the directory, the first column is the **SMILES string**, the second column is the **percent yeild**, and the last column is the **proton affinity**.\n",
    "\n",
    "At this point you may be asking what is a SMILES string as it has been mentioned several times. A SMILES string is a text based representation of a chemical compound or chemical reaction. To learn the formatting of a SMILES string please see the [Daylight Theory website](https://daylight.com/dayhtml/doc/theory/theory.smiles.html) and read through the doccumentation. You have been introduced to SMILES strings in your first assignment, but in this assignment we will learn how they can store reactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scripts Subdirectory\n",
    "\n",
    "The scripts are written in either **Python or Julia**; a language which maintains the readability, ease of use, and many features of Python but is compiled instead of interpreted (there are other advantages as well). The Python scripts end with the `.py` extension whereas the Julia scripts end with the `.jl` extension. \n",
    "\n",
    "**You will have to install Julia on the server as it is not provided. You should do this in a conda enviroment (one with RDKit as we will use it later in the assignment). You will have to install it using conda-forge with the following command:**\n",
    "\n",
    "\n",
    "```\n",
    "conda install -c conda-forge julia\n",
    "```\n",
    "\n",
    "The **Python** scripts require [RDkit](http://rdkit.org/) to function (you should have this in your conda enviroment from assignment 1).\n",
    "\n",
    "The **Julia** scripts require the installation of the [DecisionTree.jl](https://github.com/bensadeghi/DecisionTree.jl) and [CodecBase](https://github.com/bicycle1885/CodecBase.jl) packages to function properly. \n",
    "\n",
    "A breif summary of the scripts are provided below:\n",
    "\n",
    "- **`convert_to_morgan_custom.py`** - Takes two arguments: the **SMI** file for fingerprinting and the radius for the Morgan algorithm. It outputs compressed fingerprints of bitlength 2048 in the **CSV** format to **stdout**.\n",
    "\n",
    "- **`make_fp_svg_custom.py`** - Takes two arguments: the **SMI** used for input, the radius used for fingerprinting, and the bit for which you want to make an **SVG** image.\n",
    "\n",
    "- **`make_predictions.jl`** - Used to create the decision tree models and bootstrap them. It expects two files to be present: `train.csv`, and `test.csv`. This file should be run in a unique directory for each experiment as it output several files (described in the next section). This script should be run directly by the julia interpreter, *not* via the **include** mechanism.\n",
    "\n",
    "- **`bootstrap.jl`**, **`decode.jl`**, and **`prepare_data.jl`** - these are support files for the **`make_predictions.jl`** script and should be left in place. Their names are self-descriptive.\n",
    "\n",
    "- **`model.jl`** and **`decision_tree.jl`** - legacy files that can be removed and are provided for reference.\n",
    "\n",
    "Read through the code of each script and try to understand what is occuring. For Julia reference, see the [Julia Manual](https://docs.julialang.org/en/v1/manual/getting-started/) and read through as much of the tutorial as you would like.\n",
    "\n",
    "### Train36_predict14 subdirectory\n",
    "\n",
    "This directory contains results for four different radius cutoffs using the decision tree model. The input files (*train.csv* and *test.csv*) are created using the *convert_to_morgan_custom.py* script. All results in these directories (each respective to a fingerprint radius) are created by the *make_predictions.jl* and a breif description of each is given below:\n",
    "\n",
    "- `**results.csv**` - Each column represents a bootstrapped prediction for the test compounds (14 in total), the self score of the model (accuracy on the training set), and the Kappa value for the training set, and the diagnostic product ratio cutoff used to train the model. Each row has a different diagnostic product ratio cutoff.\n",
    "\n",
    "- **`set_bits.csv`** - The bits set during fingerprinting for the training set. This file is required to run other machine learning models.\n",
    "\n",
    "- **`set_bits_test.csv`** -  The same bits as above, but for the test set. Also required for other models to run.\n",
    "\n",
    "### Other_models subdirectory\n",
    "\n",
    "This directory contains **R** code used to generate the results for additional models other than decision trees. R is a programming language designed for statistics and you can find more information on using R from the [R manual](https://cran.r-project.org/manuals.html). *commands.R* requires three libraries: *tidyverse*, *parallel*, and *caret*. It must be run **after** the *make_predictions.jl* script as it requires the *set_bits.csv*  and *set_bits_test.csv* files to be created for all fingerprint radii. This script will create **CSV** files for all the models tested in our work: *glm.csv*, *knn.csv*, *pls.csv*, and *reglog.csv*. \n",
    "\n",
    "Additionally, it will read the *results.csv* created by the **Julia** scripts to create a \"dt.csv\" file. Each file has the following columns: compound ID, radius value, and the 9 cutoff values. Each row contains the test compound ID, the radius used, and the probability as calculated by each model trained with a cutoff. The Kappa value for the each model is also reported as row. These files compose the tables shown in the supporting information of the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Reading and Understanding the Paper\n",
    "\n",
    "### Question 1\n",
    "\n",
    "Read through both the manuscript and supporting information doccument and write a multi-paragraph summary that tries to answer the following questions.\n",
    "\n",
    "- What particual problem does the chemical graph based machine learning model attempt to solve/assist in solving?\n",
    "- What is the main benifit of the decision tree model we are using over other methods used in the past?\n",
    "- What is a training dataset and what specific problem with the training data must we account for? \n",
    "- What types of modes are tested to see if they can address this problem\n",
    "- Why do we use molecular fingerprinting and what information does it attempt to represent in a molecule?\n",
    "- What fingerprinting algorithm was used in the proposal?\n",
    "- How does this algorithm work?\n",
    "- What is the radius parameter and how was the radius determined in the manuscript work?\n",
    "- What type of classifier was used and what values were used to assess performance?\n",
    "- What is the test dataset and why do we need to have data that is not in the training dataset to test our model?\n",
    "- What is bootstrapping and why is it used in testing machine learning models?\n",
    "- Why do we train the model on different radii?\n",
    "- How was the robustness of the decision tree model tested?\n",
    "- How well did the model perform and how was this performance gauged?\n",
    "\n",
    "You can include any other information that you deem relevant to the manuscript in this summary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "Provide your answer to Question 1 here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Part 3 - Working with SMILES Strings for Reactions\n",
    "\n",
    "This part of the assignment will teach you how to convert molecules to SMILES strings and how to use RDKit for chemical informatics purposes. You should have RDKit set up in a conda envriroment from the frist assignment, but if you do not, go back to the assignment 1 repository and see how to set up a conda enviroment with RDKit.\n",
    "\n",
    "### Question 2\n",
    "\n",
    "Go to the supporting information section of the manuscript and choose 3 of the 36 reactions listed. Insert a picture of each reaction you choose and then below each picture provide the SMILES representation of the reaction. You can use the [following online SMILES translator](https://cactus.nci.nih.gov/translate/) to convert from structure to smiles. Simply click the `[Start Structure Editor]` button, draw in your molecule, and the click `[Submit Molecule]` and copy the corresponding SMILES string.\n",
    "\n",
    "**Note that you must provide the reaction for full credit (not just the SMILES strings)**\n",
    "\n",
    "To learn the formatting of a SMILES string reaction please see the [Daylight Theory website](https://daylight.com/dayhtml/doc/theory/theory.smiles.html) and go to the reaction section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "Provide your answer to Question 2 here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Now that you have written out 3 reactions as SMILES strings it is time to test out a reaction in RDKit. Choose **one** of the reactions that you used for the previous question (list which one was chosen) and write a python script using RDKit to store information about this reactions. \n",
    "\n",
    "Lets start by importing the RDKit packages that we will use\n",
    "\n",
    "```\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdChemReactions\n",
    "```\n",
    "\n",
    "The manual on the `rdChemReactions` package can be found [here](https://www.rdkit.org/docs/source/rdkit.Chem.rdChemReactions.html)\n",
    "\n",
    "The manual on RDKit basics can be found [here](https://www.rdkit.org/docs/GettingStartedInPython.html)\n",
    "\n",
    "Now read in your reaction using the `ReactionFromSmarts()` method. SMARTS is an extension of SMILES so your valid SMILES reaction string should also be a valid SMARTS string. If you are curious about SMARTS, you can read more on the [Daylight Theory SMARTS webpage](https://www.daylight.com/dayhtml/doc/theory/theory.smarts.html). You should use the `isSmiles=True` argument in addition to the SMILES string when calling the above method.\n",
    "\n",
    "To verify that your reaction is working correctly, you should call the `GetReactants()` and `GetProducts()` method on your reaction varaible (i.e. `rxn.GetReactants()`) and verify that the correct reactant(s) and product(s) are returned. These methods return a list of RDKit molecules so you will have to access elements of the list (i.e. `GetReactants()[x]`) and using the `Chem.MolToSmiles()` method to convert the molecule to a SMILES string.\n",
    "\n",
    "The next step is to initialize the reaction so that we can get information about it. Run the `Initialize()` method by your reaction class (`rxn.Initalize()`) and then use the `IsInitalized()` function to determine if the reaction has succesfully initalized. If this returns `True` then it has worked correctly and you can proceed to the next step.\n",
    "\n",
    "Next, we want to see what changes have been made throughout the course of the reaction. Call the `GetReactingAtoms()` method by the reaction to attempt to show what atoms have changed. The output of this method will be a tuple of X tuples (where X is the number of reactants) where each tuple refers to the atoms that have changed for that reactant. Loop through the reactants that you received from the `GetReactants()` method and see what atoms in each reactant are flagged as reacting. You can use methods such as `GetAtomWithIndex()` and `GetSymbol()` to determine which atom corresponds to which index. **This part may or may not work due to the way RDKit numbers and assigns atoms in Python. The explanation as to why it does not work is beyond the scope of this course and trying to fix it is also beyond the scope of this project. Regardless of whether or not it works, you should proceede with the following setps.** \n",
    "\n",
    "Use the RDKit plotting tools in the RDKit basics manual to plot and highlight the atoms (you only need to highlight the atoms) that are flagged as reacting for each reactant.\n",
    "\n",
    "Finally, use the `SetProp()` method to set the yeild and proton affinity properties shown for your reaction in the supporting information table. This method is called by the reaction object (i.e. `rnx.SetProp()`) and takes in two string arguments, a key and a value. The key should be the property name and the value should be the property value. Then print these properties out using the `GetProp()` method. This method is called by the reaction object and takes in the key (property name) and returns the value (property value).\n",
    "\n",
    "**In Markdown** paste all of your code over (you can use two sets of three ticks (`) to denote a code block),provide all of the output of the code (again in a code block), and provide your reactant plots and analysis on the change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Answer \n",
    "\n",
    "Provide your answer to Question 3 here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - Reaction Analysis with Machine Learning Methods\n",
    "\n",
    "### Question 4\n",
    "\n",
    "Prior to this make sure that you have install Julia as described in Part 1.\n",
    "\n",
    "Navigate over to the train36_predict14 subdirectory and make a new subdirectory called `CHM_579_run_1` and head into the `fp0` folder. Make a copy of the `train.csv` and `test.csv` and move these copies to your `CHM_579_run_1` folder.\n",
    "\n",
    "You will also need to use the updated version of the `make_prediction.jl` and the `prepare_data.jl` files. These updated files can be found in the GitHub repository.\n",
    "\n",
    "Launch Julia (type `Julia` into the terminal) and in order to run the scripts you will need to load in several Julia packages. Type the following into the Julia command prompt.\n",
    "\n",
    "```\n",
    "using Pkg\n",
    "Pkg.add(\"DecisionTree\")\n",
    "Pkg.add(\"CodecBase\")\n",
    "Pkg.add(\"CSV\")\n",
    "Pkg.add(\"DataFrames\")\n",
    "```\n",
    "\n",
    "Now we want to run the `make_prediction.jl` script in order to train a descition tree and make predictions on the test dataset. Since this script is in a different subdirectory, we will need to include it in the Julia prompt enviroment using the following command (you may need to change the path if you set this up differently.\n",
    "\n",
    "```\n",
    "include(\"../../scripts/make_predictions.jl\")\n",
    "```\n",
    "\n",
    "This should run the script and you should see output on both the command line and the output files present. \n",
    "\n",
    "In markdown, copy over the command line output, the content of the `results.csv` file. Describe what is happening in the `results.csv` file (i.e. the bootstrapping, predictions that were made, Kappa score). Based on the predictions that were made, do you think the model performed well?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Answer\n",
    "\n",
    "Provide your answer to Question 4 here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "Now, you will mix up the training and test set and rerun the model. Run the `convert_to_morgan_custom.py` on the `full_training_set.smi` file and observe the output. The file structure should look similar to the `.smi` file, but there will be Morgan fingerprints instead of SMILES strings. You should make another split (36 train, 13 test), mixing up the compounds from what they were previously. Name these files `train.csv` and `test.csv` just like before and put them in a new folder called `CHM_579_run_2`. Make sure that the `train.csv` file has 36 interies and the `test.csv` file has 13 enteries. Run the `make_predictions.jl` script in this new folder and observe the output and new resulting files. \n",
    "\n",
    "In markdown, copy over the command line output, the content of the `results.csv` file. Describe what is happening in the `results.csv` file (i.e. the bootstrapping, predictions that were made, Kappa score). Based on the predictions that were made, do you think the model performed well? Do you notice any performance difference in this model when compared to the original model? Note your findings below and explain why the model performance may be different when trained on a different set of data (Hint: Think back to how the construction of a decision tree works). If the performance is not that different then what does that say about the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "Provide your answer to Question 5 here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Now we will train and test on the same dataset. This is not something that should be done in practice to assess the quality of the model, but it is interesting to see how well the model can predict the data that it was trained on.\n",
    "\n",
    "Make a new directory called `CHM_579_run_3` and copy over `train.csv` from the original run. Now make a copy of the `train.csv` file and rename it to `test.csv`. Run the Julia script in this directory (in the same manner as before) and observe the `results.csv` file. The performance of this run (see the Kappa values) should be much higher than on the other two runs. Try to quantify this performance difference and why is this the case? What machine learning term is occuring and why is it occuring? Why do you think the model performance is not 100% if it was trained and tested on the exact same dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "Provide your answer to Question 6 here ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Question 7\n",
    "\n",
    "Choose one of the compounds present in the reactions that you chose for Part 3 (try to pick one that is relatively large). Note which compound will be used. Put this compound in a `.smi` file and run the `make_fp_svg_custom.py` at several different radii using the information in Part 1 (and the code file). Put your images here (the `.svg` files) and describe how the fingerprint changes as the radius changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "Provide your answer to Question 7 here ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
