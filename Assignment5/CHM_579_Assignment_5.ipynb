{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5: Simple Chemical Enviroment - Learning Chemical Reactivity\n",
    "\n",
    "### Due:  F 4-7-25 at 9:29 am\n",
    "\n",
    "### Name: \n",
    "\n",
    "## Part 1 - Exploring the GitHub Code for the Assignment\n",
    "\n",
    "The code for this assignment is located at the [following GitHub repository](https://github.com/chopralab/mop_reactivity_analysis) and you can clone this repository over to your account on scholar using the following command:\n",
    "\n",
    "```\n",
    "git clone https://github.com/chopralab/mop_reactivity_analysis.git\n",
    "```\n",
    "\n",
    "Aftering cloning the repository over to scholar, you can now navigate into the project directory (using `cd` or through VS Code) and see all of the files present that you have to work with (these can also be view on the GitHub repository but you cannot run the scripts here). There are two directories present in the projects base directory `ml` (machine learning) and `qm` (quantum mechanics). For this assignment, we will not use any of the scripts in the `qm` directory but you are welcome to explore the code on your own. Head over to the `ml` directory of the assignment and take a look at what subdirectories are present.\n",
    "\n",
    "### Analytes Subdirectoy\n",
    "\n",
    "This directory contains 3 **SMILES** `(.smi)` files:\n",
    "\n",
    "- `first36.smi` - The original 36 reactions used to train all models\n",
    "    \n",
    "- `test_set_14.smi` - The 14 test reactions\n",
    "    \n",
    "- `full_training_set_smi` - A concatenation of the above two files\n",
    "\n",
    "Each line of a `.smi` file contains a SMILES string representation of a compound (or reaction) and additional information (such as chemical properties) about that compound. When parsing a .smi file, you will have to tell the parser which column corresponds to which chemical property. In the `.smi` files located in the directory, the first column is the **SMILES string**, the second column is the **percent yeild**, and the last column is the **proton affinity**.\n",
    "\n",
    "At this point you may be asking what is a SMILES string as it has been mentioned several times. A SMILES string is a text based representation of a chemical compound or chemical reaction. To learn the formatting of a SMILES string please see the [Daylight Theory website](https://daylight.com/dayhtml/doc/theory/theory.smiles.html) and read through the doccumentation. You have been introduced to SMILES strings in your first assignment, but in this assignment we will learn how they can store reactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scripts Subdirectory\n",
    "\n",
    "The scripts are written in either **Python or Julia**; a language which maintains the readability, ease of use, and many features of Python but is compiled instead of interpreted (there are other advantages as well). The Python scripts end with the `.py` extension whereas the Julia scripts end with the `.jl` extension. \n",
    "\n",
    "**You will have to install Julia on the server as it is not provided. You should do this in a conda enviroment (one with RDKit as we will use it later in the assignment). You will have to install it using conda-forge with the following command:**\n",
    "\n",
    "\n",
    "```\n",
    "conda install -c conda-forge julia\n",
    "```\n",
    "\n",
    "The **Python** scripts require [RDkit](http://rdkit.org/) to function (you should have this in your conda enviroment from assignment 1).\n",
    "\n",
    "The **Julia** scripts require the installation of the [DecisionTree.jl](https://github.com/bensadeghi/DecisionTree.jl) and [CodecBase](https://github.com/bicycle1885/CodecBase.jl) packages to function properly. \n",
    "\n",
    "A breif summary of the scripts are provided below:\n",
    "\n",
    "- **`convert_to_morgan_custom.py`** - Takes two arguments: the **SMI** file for fingerprinting and the radius for the Morgan algorithm. It outputs compressed fingerprints of bitlength 2048 in the **CSV** format to **stdout**.\n",
    "\n",
    "- **`make_fp_svg_custom.py`** - Takes two arguments: the **SMI** used for input, the radius used for fingerprinting, and the bit for which you want to make an **SVG** image.\n",
    "\n",
    "- **`make_predictions.jl`** - Used to create the decision tree models and bootstrap them. It expects two files to be present: `train.csv`, and `test.csv`. This file should be run in a unique directory for each experiment as it output several files (described in the next section). This script should be run directly by the julia interpreter, *not* via the **include** mechanism.\n",
    "\n",
    "- **`bootstrap.jl`**, **`decode.jl`**, and **`prepare_data.jl`** - these are support files for the **`make_predictions.jl`** script and should be left in place. Their names are self-descriptive.\n",
    "\n",
    "- **`model.jl`** and **`decision_tree.jl`** - legacy files that can be removed and are provided for reference.\n",
    "\n",
    "Read through the code of each script and try to understand what is occuring. For Julia reference, see the [Julia Manual](https://docs.julialang.org/en/v1/manual/getting-started/) and read through as much of the tutorial as you would like.\n",
    "\n",
    "### Train36_predict14 subdirectory\n",
    "\n",
    "This directory contains results for four different radius cutoffs using the decision tree model. The input files (*train.csv* and *test.csv*) are created using the *convert_to_morgan_custom.py* script. All results in these directories (each respective to a fingerprint radius) are created by the *make_predictions.jl* and a breif description of each is given below:\n",
    "\n",
    "- `**results.csv**` - Each column represents a bootstrapped prediction for the test compounds (14 in total), the self score of the model (accuracy on the training set), and the Kappa value for the training set, and the diagnostic product ratio cutoff used to train the model. Each row has a different diagnostic product ratio cutoff.\n",
    "\n",
    "- **`set_bits.csv`** - The bits set during fingerprinting for the training set. This file is required to run other machine learning models.\n",
    "\n",
    "- **`set_bits_test.csv`** -  The same bits as above, but for the test set. Also required for other models to run.\n",
    "\n",
    "### Other_models subdirectory\n",
    "\n",
    "This directory contains **R** code used to generate the results for additional models other than decision trees. R is a programming language designed for statistics and you can find more information on using R from the [R manual](https://cran.r-project.org/manuals.html). *commands.R* requires three libraries: *tidyverse*, *parallel*, and *caret*. It must be run **after** the *make_predictions.jl* script as it requires the *set_bits.csv*  and *set_bits_test.csv* files to be created for all fingerprint radii. This script will create **CSV** files for all the models tested in our work: *glm.csv*, *knn.csv*, *pls.csv*, and *reglog.csv*. \n",
    "\n",
    "Additionally, it will read the *results.csv* created by the **Julia** scripts to create a \"dt.csv\" file. Each file has the following columns: compound ID, radius value, and the 9 cutoff values. Each row contains the test compound ID, the radius used, and the probability as calculated by each model trained with a cutoff. The Kappa value for the each model is also reported as row. These files compose the tables shown in the supporting information of the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Reading and Understanding the Paper\n",
    "\n",
    "### Question 1\n",
    "\n",
    "Read through both the manuscript and supporting information doccument and write a multi-paragraph summary that tries to answer the following questions.\n",
    "\n",
    "- What particual problem does the chemical graph based machine learning model attempt to solve/assist in solving?\n",
    "- What is the main benifit of the decision tree model we are using over other methods used in the past?\n",
    "- What is a training dataset and what specific problem with the training data must we account for? \n",
    "- What types of modes are tested to see if they can address this problem\n",
    "- Why do we use molecular fingerprinting and what information does it attempt to represent in a molecule?\n",
    "- What fingerprinting algorithm was used in the proposal?\n",
    "- How does this algorithm work?\n",
    "- What is the radius parameter and how was the radius determined in the manuscript work?\n",
    "- What type of classifier was used and what values were used to assess performance?\n",
    "- What is the test dataset and why do we need to have data that is not in the training dataset to test our model?\n",
    "- What is bootstrapping and why is it used in testing machine learning models?\n",
    "- Why do we train the model on different radii?\n",
    "- How was the robustness of the decision tree model tested?\n",
    "- How well did the model perform and how was this performance gauged?\n",
    "\n",
    "You can include any other information that you deem relevant to the manuscript in this summary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "Provide your answer to Question 1 here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Part 3 - Working with SMILES Strings for Reactions\n",
    "\n",
    "This part of the assignment will teach you how to convert molecules to SMILES strings and how to use RDKit for chemical informatics purposes. You should have RDKit set up in a conda envriroment from the frist assignment, but if you do not, go back to the assignment 1 repository and see how to set up a conda enviroment with RDKit.\n",
    "\n",
    "### Question 2\n",
    "\n",
    "Go to the supporting information section of the manuscript and choose 3 of the 36 reactions listed. Insert a picture of each reaction you choose and then below each picture provide the SMILES representation of the reaction. You can use the [following online SMILES translator](https://cactus.nci.nih.gov/translate/) to convert from structure to smiles. Simply click the `[Start Structure Editor]` button, draw in your molecule, and the click `[Submit Molecule]` and copy the corresponding SMILES string.\n",
    "\n",
    "**Note that you must provide the reaction for full credit (not just the SMILES strings)**\n",
    "\n",
    "To learn the formatting of a SMILES string reaction please see the [Daylight Theory website](https://daylight.com/dayhtml/doc/theory/theory.smiles.html) and go to the reaction section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "Provide your answer to Question 2 here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Now that you have written out 3 reactions as SMILES strings it is time to test out a reaction in RDKit. Choose **one** of the reactions that you used for the previous question (list which one was chosen) and write a python script using RDKit to store information about this reactions. \n",
    "\n",
    "Lets start by importing the RDKit packages that we will use\n",
    "\n",
    "```\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdChemReactions\n",
    "```\n",
    "\n",
    "The manual on the `rdChemReactions` package can be found [here](https://www.rdkit.org/docs/source/rdkit.Chem.rdChemReactions.html)\n",
    "\n",
    "The manual on RDKit basics can be found [here](https://www.rdkit.org/docs/GettingStartedInPython.html)\n",
    "\n",
    "Now read in your reaction using the `ReactionFromSmarts()` method. SMARTS is an extension of SMILES so your valid SMILES reaction string should also be a valid SMARTS string. If you are curious about SMARTS, you can read more on the [Daylight Theory SMARTS webpage](https://www.daylight.com/dayhtml/doc/theory/theory.smarts.html). You should use the `isSmiles=True` argument in addition to the SMILES string when calling the above method.\n",
    "\n",
    "To verify that your reaction is working correctly, you should call the `GetReactants()` and `GetProducts()` method on your reaction varaible (i.e. `rxn.GetReactants()`) and verify that the correct reactant(s) and product(s) are returned. These methods return a list of RDKit molecules so you will have to access elements of the list (i.e. `GetReactants()[x]`) and using the `Chem.MolToSmiles()` method to convert the molecule to a SMILES string.\n",
    "\n",
    "The next step is to initialize the reaction so that we can get information about it. Run the `Initialize()` method by your reaction class (`rxn.Initalize()`) and then use the `IsInitalized()` function to determine if the reaction has succesfully initalized. If this returns `True` then it has worked correctly and you can proceed to the next step.\n",
    "\n",
    "Next, we want to see what changes have been made throughout the course of the reaction. Call the `GetReactingAtoms()` method by the reaction to attempt to show what atoms have changed. The output of this method will be a tuple of X tuples (where X is the number of reactants) where each tuple refers to the atoms that have changed for that reactant. Loop through the reactants that you received from the `GetReactants()` method and see what atoms in each reactant are flagged as reacting. You can use methods such as `GetAtomWithIndex()` and `GetSymbol()` to determine which atom corresponds to which index. **This part may or may not work due to the way RDKit numbers and assigns atoms in Python. The explanation as to why it does not work is beyond the scope of this course and trying to fix it is also beyond the scope of this project. Regardless of whether or not it works, you should proceede with the following setps.** \n",
    "\n",
    "Use the RDKit plotting tools in the RDKit basics manual to plot and highlight the atoms (you only need to highlight the atoms) that are flagged as reacting for each reactant.\n",
    "\n",
    "Finally, use the `SetProp()` method to set the yeild and proton affinity properties shown for your reaction in the supporting information table. This method is called by the reaction object (i.e. `rnx.SetProp()`) and takes in two string arguments, a key and a value. The key should be the property name and the value should be the property value. Then print these properties out using the `GetProp()` method. This method is called by the reaction object and takes in the key (property name) and returns the value (property value).\n",
    "\n",
    "**In Markdown** paste all of your code over (you can use two sets of three ticks (`) to denote a code block),provide all of the output of the code (again in a code block), and provide your reactant plots and analysis on the change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Answer \n",
    "\n",
    "Provide your answer to Question 3 here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - Reaction Analysis with Machine Learning Methods\n",
    "\n",
    "### Question 4\n",
    "\n",
    "Prior to this make sure that you have install Julia as described in Part 1.\n",
    "\n",
    "Navigate over to the train36_predict14 subdirectory and make a new subdirectory called `CHM_579_run_1` and head into the `fp0` folder. Make a copy of the `train.csv` and `test.csv` and move these copies to your `CHM_579_run_1` folder.\n",
    "\n",
    "You will also need to use the updated version of the `make_prediction.jl` and the `prepare_data.jl` files. These updated files can be found in the GitHub repository.\n",
    "\n",
    "Launch Julia (type `Julia` into the terminal) and in order to run the scripts you will need to load in several Julia packages. Type the following into the Julia command prompt.\n",
    "\n",
    "```\n",
    "using Pkg\n",
    "Pkg.add(\"DecisionTree\")\n",
    "Pkg.add(\"CodecBase\")\n",
    "Pkg.add(\"CSV\")\n",
    "Pkg.add(\"DataFrames\")\n",
    "```\n",
    "\n",
    "Now we want to run the `make_prediction.jl` script in order to train a descition tree and make predictions on the test dataset. Since this script is in a different subdirectory, we will need to include it in the Julia prompt enviroment using the following command (you may need to change the path if you set this up differently.\n",
    "\n",
    "```\n",
    "include(\"../../scripts/make_predictions.jl\")\n",
    "```\n",
    "\n",
    "This should run the script and you should see output on both the command line and the output files present. \n",
    "\n",
    "In markdown, copy over the command line output, the content of the `results.csv` file. Describe what is happening in the `results.csv` file (i.e. the bootstrapping, predictions that were made, Kappa score). Based on the predictions that were made, do you think the model performed well?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Answer\n",
    "\n",
    "Provide your answer to Question 4 here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "Now, you will mix up the training and test set and rerun the model. Run the `convert_to_morgan_custom.py` on the `full_training_set.smi` file and observe the output. The file structure should look similar to the `.smi` file, but there will be Morgan fingerprints instead of SMILES strings. You should make another split (36 train, 13 test), mixing up the compounds from what they were previously. Name these files `train.csv` and `test.csv` just like before and put them in a new folder called `CHM_579_run_2`. Make sure that the `train.csv` file has 36 interies and the `test.csv` file has 13 enteries. Run the `make_predictions.jl` script in this new folder and observe the output and new resulting files. \n",
    "\n",
    "In markdown, copy over the command line output, the content of the `results.csv` file. Describe what is happening in the `results.csv` file (i.e. the bootstrapping, predictions that were made, Kappa score). Based on the predictions that were made, do you think the model performed well? Do you notice any performance difference in this model when compared to the original model? Note your findings below and explain why the model performance may be different when trained on a different set of data (Hint: Think back to how the construction of a decision tree works). If the performance is not that different then what does that say about the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "Provide your answer to Question 5 here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Now we will train and test on the same dataset. This is not something that should be done in practice to assess the quality of the model, but it is interesting to see how well the model can predict the data that it was trained on.\n",
    "\n",
    "Make a new directory called `CHM_579_run_3` and copy over `train.csv` from the original run. Now make a copy of the `train.csv` file and rename it to `test.csv`. Run the Julia script in this directory (in the same manner as before) and observe the `results.csv` file. The performance of this run (see the Kappa values) should be much higher than on the other two runs. Try to quantify this performance difference and why is this the case? What machine learning term is occuring and why is it occuring? Why do you think the model performance is not 100% if it was trained and tested on the exact same dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "Provide your answer to Question 6 here ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Question 7\n",
    "\n",
    "Choose one of the compounds present in the reactions that you chose for Part 3 (try to pick one that is relatively large). Note which compound will be used. Put this compound in a `.smi` file and run the `make_fp_svg_custom.py` at several different radii using the information in Part 1 (and the code file). Put your images here (the `.svg` files) and describe how the fingerprint changes as the radius changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "Provide your answer to Question 7 here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Creating a chat model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chat models are language models that use a sequence of messages as inputs and return messages as outputs. This tutorial will go over how to create a chat model using OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, create a new conda environment with python 3.10 by entering the following code into the terminal.\n",
    "\n",
    "```\n",
    "conda create -n assignment5 python=3.10\n",
    "conda install -n assignment5 ipykernel --update-deps --force-reinstall\n",
    "```\n",
    "\n",
    "We need to install langchain dependencies to the conda environment. LangChain provides a framework for building applications with language models, integrating components such as memory, chains, and agents. LangGraph extends LangChain by enabling structured, multi-step execution flows, which can be useful for complex AI-driven tasks.\n",
    "\n",
    "```\n",
    "module load anaconda\n",
    "conda activate assignment5\n",
    "pip install langchain\n",
    "pip install langgraph\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will set up interaction with the OpenAI LLM using python code by installing the OpenAI package. This package enables access to OpenAI’s models, such as GPT-4 and GPT-3.5, through the LangChain framework. It abstracts API calls and provides tools for managing tokens, formatting prompts, and handling responses efficiently.\n",
    "\n",
    "```pip install langchain-openai```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To interact with OpenAI’s models, we need to authenticate our requests using an API key. An API key (Application Programming Interface key) is a unique identifier used to authenticate and authorize requests between your Python code and an API. It acts like a password, granting access to the API’s services while ensuring that only authorized users can make requests. The API we will be using is paid by ChopraLab; each usage is linked to this account. The API key cannot be posted on GitHub, since anyone could use it and potentially rack up high charges or exploit the key. In the lab, we will give you the key, but you must not use it for things other than this assignment and protect it from being leaked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "#Set API key if it's not already set\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = \"Put_key_here\"\n",
    "\n",
    "from langchain.chat_models import init_chat_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize a chat model from OpenAI using LangChain’s init_chat_model function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Initialize a chat model from OpenAI\n",
    "model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "response=model.invoke(\"How many hydrogen bonds does deca-alanine have?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try doing another invoke call asking a question about deca alanine without mentioning the name. How does the chatbot respond and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, run the following lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    response = model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "# Define the (single) node in the graph\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "# Add memory\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "query = \"Tell me how many bonds are in deca alanine.\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()  # output contains all messages in state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "query = \"What are the commercial uses of it?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the above lines added to the chat model, how does it respond to a question about deca alanine without mentioning the name? What gives it this functionality?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer here.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 6: Prompt Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a prompt template adds extra information to prompt that is sent to the LLM that the user does not see in their request. This extra information is included in the prompt but is invisible to the end-user, allowing the LLM to focus on responding to the core user query while receiving all necessary context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You talk like a pirate. Answer all questions to the best of your ability.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    prompt = prompt_template.invoke(state)\n",
    "    response = model.invoke(prompt)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "query = \"What is decalanine\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "query = \"What are the commercial uses of it?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What would be some useful cases for prompt templates for asking questions about the paper in Part 2?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer here.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 7: Document loaders and Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last part of this tutorial, we will show how to embed multiple documents into an agent. We will go over more about making an agent in assignment 7, but for now we will focus on the document loading bit. A document loader in LangChain is a tool that helps you load and process documents from various sources (such as PDFs, text files, web pages, databases, etc.) so that they can be used for further processing, like embedding, searching, or summarization. An embedding is a numerical representation of text, images, or other data, where similar data points have similar representations in a high-dimensional space. In the context of natural language processing (NLP), embeddings convert words, sentences, or entire documents into vectors (lists of numbers) that capture their meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First run the following line in the terminal. Pypdf is a python library used for working with PDF files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```pip install langchain-community pypdf```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is loading the pdf. It must be in the same folder as your assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = \"pdf_here\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will be splitting the pdf document into smaller, manageable chuncks for easier processing by the language model. Here, each chunk will have a maximum size of 1000 characters and each will overlap by 200 with the next chunk. This is important because it ensures that there is some context carried over between chunks, which helps the model maintain coherence across different parts of the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "len(all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using OpenAI's embedding models to convert the pdf text into dense vector representations. The vector will capture the essence of the meaning behind the text, making it possible to compare the text with other texts based on their numberical (and thus semantic) similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "vector_1 = embeddings.embed_query(all_splits[0].page_content)\n",
    "vector_2 = embeddings.embed_query(all_splits[1].page_content)\n",
    "\n",
    "assert len(vector_1) == len(vector_2)\n",
    "print(f\"Generated vectors of length {len(vector_1)}\\n\")\n",
    "print(vector_1[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chroma is an open-source vector database used for storing and retrieving embeddings efficiently. We import it here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```pip install langchain-chroma```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "ids = vector_store.add_documents(documents=all_splits)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, we perform a semantic similarity search using a vector database (Chroma) to find the most relevant document based on the query. Replace the text \"QUESTION HERE\" with a relevant question you would like to find about the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "results = vector_store.similarity_search_with_score(\"QUESTION HERE\")\n",
    "doc, score = results[0]\n",
    "print(f\"Score: {score}\\n\")\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a retriever tool to access documents from the embedding. This will be used to create an agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "\n",
    "@tool\n",
    "def retriever(query: str):\n",
    "    '''Tool for accessing documents from embedding based on a provided query. Use this if the user asks for specific information\n",
    "    '''\n",
    "    return str(vector_store.similarity_search(query, k=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import relevant functionality\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# Create the agent\n",
    "memory = MemorySaver()\n",
    "model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "tools = [retriever]\n",
    "agent_executor = create_react_agent(model, tools, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Use the agent\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "for step in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"QUESTION HERE\")]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit the above code for this part to load the pdf of the paper from Part 2. Ask the agent relevant questions about the paper. You can add more cells to ask more questions. Does the agent respond correctly to your questions? What are the scores of these answers? Please provide a throuough analysis related to these questions in the answer cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer here.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
