{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 6: Chemical Enviroment - Molecular Docking and Drug Design\n",
    "\n",
    "### Due:  M 4-28-25 at 9:29 am\n",
    "\n",
    "### Name:\n",
    "\n",
    "This assignment has been split into three parts. Each part has a general procedure for their portion of the assignment as well as a discussion section. Please be sure to address all parts of the discussion as your responses to this section are what determine your grade on this assignment.\n",
    "\n",
    "## Part A - Creating an AI agent\n",
    " \n",
    "#### Objective\n",
    "\n",
    "The object of this part of the assignment is to teach you how to create your own AI agent through showing you an example of how to do so.\n",
    "\n",
    "#### Procedure\n",
    "\n",
    "First we need to load the conda environment from the last assignment.\n",
    "\n",
    "```\n",
    "module load anaconda\n",
    "conda activate assignment5\n",
    "pip install langchain\n",
    "pip install langgraph\n",
    "pip install langchain-openai\n",
    "\n",
    "```\n",
    "\n",
    "Agents are essestially chatbots that have access to tools. Tools are custom python functions that you define that agents determine what to put in and observe what is outputted. \n",
    "Here we will create a tool from the pubchem rest api. Here is a link to the tutorial of how the api is structured: https://pubchem.ncbi.nlm.nih.gov/docs/pug-rest-tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "#Set API key if it's not already set\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = \"put_key_here\"\n",
    "\n",
    "from langchain.chat_models import init_chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "import requests\n",
    "\n",
    "@tool\n",
    "def get_compound_properties(compound_name, properties=\"MolecularFormula,MolecularWeight\"):\n",
    "    \"\"\"\n",
    "    Fetches specified properties of a compound from the PubChem REST API by name.\n",
    "\n",
    "    Parameters:\n",
    "        compound_name (str): The name of the compound (e.g., \"aspirin\").\n",
    "        properties (str): Comma-separated properties to fetch (default: \"MolecularFormula,MolecularWeight\").\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the requested properties or an error message.\n",
    "    \"\"\"\n",
    "    base_url = \"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/name\"\n",
    "    url = f\"{base_url}/{compound_name}/property/{properties}/JSON\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an error for HTTP issues\n",
    "        data = response.json()\n",
    "        \n",
    "        # Extract properties\n",
    "        return data.get(\"PropertyTable\", {}).get(\"Properties\", [{}])[0]\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return {\"error\": str(e)}\n",
    "    \n",
    "@tool\n",
    "def get_bioassay_names(compound_name):\n",
    "    \"\"\"\n",
    "    Fetches bioassay names associated with a given compound from the PubChem REST API.\n",
    "\n",
    "    Parameters:\n",
    "        compound_name (str): The name of the compound (e.g., \"aspirin\").\n",
    "\n",
    "    Returns:\n",
    "        list: A list of bioassay names or an error message.\n",
    "    \"\"\"\n",
    "    # Step 1: Get the Compound CID\n",
    "    cid_url = f\"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/name/{compound_name}/cids/JSON\"\n",
    "\n",
    "    try:\n",
    "        cid_response = requests.get(cid_url)\n",
    "        cid_response.raise_for_status()\n",
    "        cid_data = cid_response.json()\n",
    "\n",
    "        # Extract first available CID\n",
    "        cids = cid_data.get(\"IdentifierList\", {}).get(\"CID\", [])\n",
    "        if not cids:\n",
    "            return {\"error\": f\"No CID found for compound: {compound_name}\"}\n",
    "\n",
    "        cid = cids[0]  # Use the first CID\n",
    "\n",
    "        # Step 2: Retrieve Bioassay Summary for the Compound\n",
    "        bioassay_url = f\"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/cid/{cid}/assaysummary/JSON\"\n",
    "        bioassay_response = requests.get(bioassay_url)\n",
    "        bioassay_response.raise_for_status()\n",
    "        bioassay_data = bioassay_response.json()\n",
    "\n",
    "        # Extract assay names\n",
    "        assays = bioassay_data.get(\"AssaySummaries\", [])\n",
    "        bioassay_names = [assay.get(\"Name\", f\"Assay {assay.get('AID')}\") for assay in assays]\n",
    "\n",
    "        return bioassay_names if bioassay_names else {\"error\": \"No bioassays found for this compound.\"}\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return {\"error\": str(e)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant functionality\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "\n",
    "# Create the agent\n",
    "memory = MemorySaver()\n",
    "model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "tools = [get_compound_properties, get_bioassay_names]\n",
    "agent_executor = create_react_agent(model, tools, checkpointer=memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"Can you get me the names of bioassays for this drug\")]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "From the above tutorial provided, create your own agent using any api that has memory. You can edit the above cells or add new ones to complete this task. Ask it some relevant questions to your research (or interest). Play around with its functionality and discuss this in a paragraph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B - Use of Docking Methods for Drug Design\n",
    "\n",
    "### Sub Part 1 - Docking FDA Approved Compounds to a Target\n",
    "\n",
    "#### Objective\n",
    "\n",
    "The object of this part of the assignment is to teach you how to submit CANDOCK jobs. These jobs find the interactions between a library of small of small molecules and a receptor (or target).\n",
    "\n",
    "#### Procedure\n",
    "\n",
    "#### Step 1 - Setup CANDOCK\n",
    "\n",
    "Since CANDOCK's location is non-standard, you will need to tell the computer where to find the executables for CANDOCK. To do this, use the following command:\n",
    "\n",
    "```\n",
    "export PATH=/depot/gchopra-class/apps/v0.4.3/modules:$PATH\n",
    "```\n",
    "\n",
    "You can add this line to the ~/.bashrc file so that you do not have to run it every time you log into the computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "export PATH=/depot/gchopra-class/apps/v0.6.0_chm579/modules:$PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can set up the folder system however you would like for this assignment. I reccomend making one folder for each part. Use the below cell to set up the foldering however you would like or do it on VS Code beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up folders here in this cell (or do it on VS Code) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 - Obtain a Receptor\n",
    "\n",
    "For this assignment, we will use the kinase FLT3 as our target. We first need to download this structure and place it in a new directory corresponding to this part of the assignment. The file you downloaded must be renamed as receptor.pdb. If you have completed the previous step, use the following command to do so for the PDB ID 4XUF. Note we will use as an example for future steps.\n",
    "\n",
    "```\n",
    "wget https://files.rcsb.org/view/4XUF.pdb \n",
    "```\n",
    "\n",
    "4XUF already has a ligand in it (RCSB will tell you this), you must remove it. There will be a three alphanumeric code for this ligand. In our case it is P30, you can remove it using a text editor, or with this command:\n",
    "\n",
    "```\n",
    "cat 4XUF.pdb | grep -v P30 | grep ' A ' > receptor.pdb\n",
    "```\n",
    "\n",
    "Note: CANDOCK is able to dock with crystal waters and cofactor (such as metal ions, NAD, etc). Thus, these do NOT need to be removed.\n",
    "\n",
    "Also note: If you plan on using CANDOCK for your final project, pick a target that may be implicated in a disease pathway that you are interested in studying, or come from a previous assignment for this course. Once this target is selected, search for it on UniProt.org or rcsb.org and find a solved structure for this target (make sure you select a structure with the appropriate domains)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wget https://files.rcsb.org/view/4XUF.pdb \n",
    "cat 4XUF.pdb |grep -v P30 | grep ' A ' > receptor.pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3 - Determine the Binding Site\n",
    "\n",
    "In order to dock compounds to a target, one must give a binding site on the target in question. Fortunately, CANDOCK is able to predict binding sites de novo if no binding sites are given by the user. These binding sites are given as text files and are typically named receptor/site.cen (since we called our target receptor) and is placed in a directory named after the target.\n",
    "\n",
    "If you wish for candock to predict a binding site for you, use the following command, but note that this is not needed as this step will be run automatically.\n",
    "\n",
    "```\n",
    "submit_candock_module.sh find_centroids\n",
    "```\n",
    "\n",
    "This will create a SLURM job and submit it with sbatch automatically. If this step fails (no receptor/site.cen file is present once the job finishes), you must give a binding site yourself, Contact the instructor if this is the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_candock_module.sh find_centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you are using CANDOCK for your final project, then the next section maybe useful to you. Otherwise, continue to Section 04.**\n",
    "\n",
    "If you know or are interested in, a binding site for your target create a text file named 'receptor/site.cen' with the following contents. Each line represents a sphere centered around (x,y,z) with radius r. The number in the lefthand column should always be 1 unless you are specifying more than one binding site. This should look like the following example:\n",
    "\n",
    "1 x1 y1 z1 r1\n",
    "\n",
    "1 x2 y2 z2 r2\n",
    "\n",
    "1 x3 y3 z3 r3\n",
    "\n",
    "....etc....\n",
    "\n",
    "If you do not know the binding site, do not create any new files. CANDOCK will attempt to determine the binding site automatically and save the result to receptor/site.cen ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 04 - Prepare the Ligands\n",
    "\n",
    "Copy the following file to the directory that contains receptor.pdb:\n",
    "\n",
    "```\n",
    "cp /depot/gchopra-class/data/lab_7_compounds.mol2 ligands.mol2\n",
    "prep_fragments.sh\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp /depot/gchopra-class/data/lab_7_compounds.mol2 ligands.mol2\n",
    "prep_fragments.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the command completes, you should have the following new files: prepared_ligands.pdb, seeds.txt, and seeds.pdb. You can open seeds.pdb in PyMOL to see how CANDOCK fragmented your compounds of interest. If you did this step, skip to step 05.\n",
    "\n",
    "**If you are using CANDOCK for your final project, the next section may be useful to you. Otherwise, skip to Step 05.**\n",
    "\n",
    "Note: submitting your own compounds\n",
    "If you would like to use your own ligands (possibly ones that you find interesting), you can submit a version of your files in the Tripos mol2 format. An online tool exists to convert most formats to mol2 (http://pasilla.health.unm.edu/tomcat/biocomp/convert). Place your ligands as the file ligands.mol2 in the same directory as receptor.pdb. Let's use P30 from 4XUF as an example. Goto rcsb.org and search for the ligand P30. You should find the page: https://www3.rcsb.org/ligand/P30 . Use the button in the top right corner to download the Ideal SDF file. Submit this file to the webserver and download the result. Copy this file as ligands.mol2 in the directly with receptor.pdb in it. Ensure that you do NOT have a prepared_liands.pdb file or a seeds.txt file in this directory! Finally, run the following command (note this assumes you are docking a small number of ligands):\n",
    "```\n",
    "prep_fragments.sh\n",
    "```\n",
    "\n",
    "#### Step 5 -  Dock the Ligand Fragments\n",
    "\n",
    "Now that you have a receptor (`receptor.pdb`), a binding site (`receptor/site.cen` will only exist if you ran `find_centroids.sh` or have provided your own), and ligands to dock (`prepared_ligands.pdb`) you can now start docking! We're going to do this in stages so that you understand how the process works.\n",
    "\n",
    "To dock the fragments, use the following command. Like the step for binding site determination, you do not need to do this explicitly as it will be done automatically in Step 06.\n",
    "\n",
    "```\n",
    "submit_candock_module.sh dock_fragments\n",
    "```\n",
    "\n",
    "(These are notes for trouble shooting and do not need to be done! Feel free to move onto Step 06)\n",
    "\n",
    "You will get a new directory called `receptor/top_seeds/` which contains the results of fragment docking performed on the seeds in `seeds.pdb`. You can open the files in this directory using PyMOL to see how CANDOCK placed these fragments in your binding pocket.\n",
    "\n",
    "Once you have the fragments docked, you can complete the docking procedure by linking the fragments together. Before you begin this step, make sure that the directory top_seeds exists in the directory that you are doing docking in. Also, check the file slurm-###### for any erros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_candock_module.sh dock_fragments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6 - Link the fragments\n",
    "\n",
    "Technically speaking, this is the only command you need to submit a CANDOCK job as it will run any required previous steps if needed. This is the final step in running CANDOCK and will produce a directory call receptor/docked that will contain the docked conformations of the ligands.\n",
    "\n",
    "```\n",
    "submit_candock_module.sh link_fragments\n",
    "```\n",
    "\n",
    "Note that for the sake of time, CANDOCK has been configured for this assignment in a way that it will generate fewer conformations than normal. If you are using CANDOCK for your final project, you may want to configure it to generate more. Ask an instructor if this is the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_candock_module.sh link_fragments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7 - Look at the Results\n",
    "\n",
    "After the linking step has completed, there will be a directory called `receptor/docked` in the directory that you submitted jobs in. In this directory, a file will be created for all of the compounds that you docked against. These files contain CANDOCK's predicted conformations and corresponding score. Since these files are standard PDB files, they can be opened in PyMOL directly. However, PyMOL has issues with opening these files directly. Thus, it is recommended to follow the following steps:\n",
    "\n",
    "```\n",
    "cd receptor/\n",
    "extract_results.sh\n",
    "```\n",
    "\n",
    "You will get two new files in this directory, `scores.csv` which is an Excel file with CANDOCK's predicted scores, and `all.pse` which is a PyMOL sessions. The order of the compounds in this session are in decreasing binding affinity. If a compound is missing from either file, CANDOCK has predicted that this compound is a non-binder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd receptor/\n",
    "extract_result.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will get two new files in this directory, scores.csv which is an Excel file with CANDOCK's predicted scores, and all.pse which is a PyMOL sessions. The order of the compounds in this session are in decreasing binding affinity. If a compound is missing from either file, CANDOCK has predicted that this compound is a non-binder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub Part 2 - Design of New Compounds\n",
    "\n",
    "#### Objective\n",
    "\n",
    "This assignment will teach you how to use CANDOCK to make changes to existing binders (`lead.mol2`) for a given target using a collection of chemical fragments (`additional.mol2`).\n",
    "\n",
    "#### Lead optimization\n",
    "\n",
    "#### Against a single target\n",
    "\n",
    "A recent paper published by the pharmaceutical company Hoffman La-Roche (citation at the end of section) describes an effort to optimize a DPP-IV inhibitor. The goal was to optimize a lead by replacing an R group with various other fragments. Two files, `lead.mol2` and `additional.mol2` have been prepared with this lead and the additional fragments respectively. Download them and place them in an empty directory. Next, download the protein structure mentioned in the paper (3OC0) and place into the subdirectory targets/ (remember to clean it up first!). Then create the following script and run it.\n",
    "\n",
    "```\n",
    "cp /depot/gchopra-class/data/additional.mol2 .\n",
    "cp /depot/gchopra-class/data/lead.mol2 .\n",
    "\n",
    "mkdir targets\n",
    "cp /depot/gchopra-class/data/target.pdb targets/\n",
    "\n",
    "export CANDOCK_ligand=lead.mol2\n",
    "export CANDOCK_fragment_mol=additional.mol2\n",
    "\n",
    "prep_fragments.sh\n",
    "export CANDOCK_target_dir=targets\n",
    "export CANDOCK_lipinski_nhs=5\n",
    "export CANDOCK_lipinski_ohs=5\n",
    "\n",
    "\n",
    "submit_candock_module.sh design_ligands\n",
    "```\n",
    "\n",
    "You will get the files `designed_1.mol2` and `designed2.mol2`. Do they match the compounds suggested by the authors?\n",
    "\n",
    "A Real-World Perspective on Molecular Design Kuhn, B. et al. Journal of Medicinal Chemistry 2016 59 (9), 4087-4102 DOI: 10.1021/acs.jmedchem.5b01875"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add bash code for organization here ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp /depot/gchopra-class/data/additional.mol2 .\n",
    "cp /depot/gchopra-class/data/lead.mol2 .\n",
    "\n",
    "mkdir targets\n",
    "cp /depot/gchopra-class/data/target.pdb targets/\n",
    "\n",
    "export CANDOCK_ligand=lead.mol2\n",
    "export CANDOCK_fragment_mol=additional.mol2\n",
    "\n",
    "prep_fragments.sh\n",
    "export CANDOCK_target_dir=targets\n",
    "export CANDOCK_lipinski_nhs=5\n",
    "export CANDOCK_lipinski_ohs=5\n",
    "\n",
    "\n",
    "submit_candock_module.sh design_ligands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Against multiple targets\n",
    "\n",
    "The procedure for profile based design is similar to the one for single targets, the only difference is that one places more targets in the targets/ directory. To give CANDOCK targets that you wish to decrease binding affinity to, you create an additional folder called atargets. **Create a new directory from scratch (IE separate from any previous jobs) and run the following commands**:\n",
    "\n",
    "```\n",
    "cp /depot/gchopra-class/data/additional.mol2 .\n",
    "cp /depot/gchopra-class/data/lead.mol2 .\n",
    "\n",
    "mkdir targets\n",
    "cp /depot/gchopra-class/data/target.pdb targets/\n",
    "\n",
    "mkdir atargets\n",
    "cp /depot/gchopra-class/data/antitarget.pdb atargets/\n",
    "\n",
    "export CANDOCK_ligand=lead.mol2\n",
    "export CANDOCK_fragment_mol=additional.mol2\n",
    "\n",
    "prep_fragments.sh\n",
    "\n",
    "export CANDOCK_target_dir=targets\n",
    "export CANDOCK_antitarget_dir=atargets\n",
    "export CANDOCK_lipinski_nhs=5\n",
    "export CANDOCK_lipinski_ohs=5\n",
    "export CANDOCK_seeds_to_avoid=2\n",
    "\n",
    "submit_candock_module.sh design_ligands\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add bash code for organization here ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp /depot/gchopra-class/data/additional.mol2 .\n",
    "cp /depot/gchopra-class/data/lead.mol2 .\n",
    "\n",
    "mkdir targets\n",
    "cp /depot/gchopra-class/data/target.pdb targets/\n",
    "\n",
    "mkdir atargets\n",
    "cp /depot/gchopra-class/data/antitarget.pdb atargets/\n",
    "\n",
    "export CANDOCK_ligand=lead.mol2\n",
    "export CANDOCK_fragment_mol=additional.mol2\n",
    "\n",
    "prep_fragments.sh\n",
    "\n",
    "export CANDOCK_target_dir=targets\n",
    "export CANDOCK_antitarget_dir=atargets\n",
    "export CANDOCK_lipinski_nhs=5\n",
    "export CANDOCK_lipinski_ohs=5\n",
    "export CANDOCK_seeds_to_avoid=2\n",
    "\n",
    "submit_candock_module.sh design_ligands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design of new scaffolds\n",
    "\n",
    "**Note: you can ignore this section of assignment. It is presented to you only in hope that it may help you for your final project. It is not required for this lab.**\n",
    "\n",
    "CANDOCK has the ability to design new compounds from the seeds database generated in Step 05. Create a new directory (separate from the one you did docking in) and copy the files seeds.pdb and seeds.txt into this new directory. Create a subdirectory called targets in this location and and copy the receptor directory from your previous run into this subdirectory along with `receptor.pdb`. The directory structure should look like the following:\n",
    "\n",
    "```\n",
    "$ ls\n",
    "\n",
    "seeds.txt seeds.pdb targets/\n",
    "\n",
    "$ ls targets/\n",
    "\n",
    "receptor.pdb receptor/\n",
    "\n",
    "$ ls targets/receptor/\n",
    "\n",
    "top_seeds/ site.cen gridpdb_hcp.pdb\n",
    "\n",
    "export CANDOCK_target_dir=targets\n",
    "submit_candock_module.sh design_ligands\n",
    "```\n",
    "Congrats! Now you're creating new designs! When the job completes, you will get files named like `designed#.pdb`. These files contain the designs generated by the program. The docked version of these compounds is present in `targets/receptor/docked/` . You can use the extract script to get the scores of these compounds.\n",
    "\n",
    "[CANDOCK README File](https://web.ics.purdue.edu/~gchopra/class/public/assignments/lab4c/README.html)\n",
    "\n",
    "[CANDOCK Paper](https://pubs.acs.org/doi/abs/10.1021/acs.jcim.9b00686#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Questions\n",
    "\n",
    "#### Sub Part 1 \n",
    "\n",
    "1. For your writeup, you should include images of the docked poses and docking scores of the compound. \n",
    "    - Which drugs bind best to your protein of choice? \n",
    "    - Did you expect this? Why or why not? \n",
    "    - Note that the three letter codes ( P30, KIM, etc ) are all kinase inhibitors!\n",
    "2. Include images of the interactions between some of the high scoring molecules and the low scoring ones. \n",
    "    - What interactions do you believe helped make the higher scoring compounds bind better than the low scoring ones?\n",
    "3. Open all.pse along with the original 4XUF file. \n",
    "    - How well did CANDOCK predict the binding pose of P30? \n",
    "    - Using the arrows in PyMOL's window, checkout the multiple poses generated by CANDOCK. \n",
    "    - Report CANDOCK scores of the well predicted pose and the top pose of the P30 molecule\n",
    "4. Part of CANDOCK's linking procedure includes an energy minimization procedure. \n",
    "    - Did your target's conformation change while docking? If so, by much?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sub Part 2\n",
    "\n",
    "1. Examine the designs created by CANDOCK. \n",
    "    - Do they match what is listed in the paper?\n",
    "2. How does the addition of the antitarget change the designs created?\n",
    "3. Include images of some of the designed ligands and discuss their interactions at the binding site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C - Combined molecular Graph Neural Networks and Structural Docking to Select Potent PD-1/PD-L1 Small Molecule Inhibitors\n",
    "\n",
    "#### Introduction\n",
    "\n",
    "The Programmable Cell Death Protein 1/Programmable Death-Ligand 1 (PD-1/PD-L1) interaction is an immune checkpoint utilized by cancer cells to enhance immune suppression. There exists a huge need to develop small molecule drugs that are fast acting, cheap, and readily bioavailable compared to antibodies. Unfortunately, synthesizing and validating large libraries of small-molecule to inhibit PD-1/PD-L1 interaction in a blind manner is a both time-consuming and expensive. Here we use a machine learning method call EGNN which is based on graph neural networks (GNNs) and docking scores. We call them local and global features respectively. GNNs are models which use message passing between nodes and edges of graphs. These graphs can be anything. In our case nodes are atoms and edges are bonds of molecules. GNNs retain a state with information of its neighbours with an arbitrary depth. We call it as the sub graph radius. On the other hand, docking scores can be used as global features which captures interactions of the molecules with the target. Therefore, EGNN model take both local and global features to select potent small molecule inhibitors.\n",
    "\n",
    "[Graph Neural Networks - A Review of Methods and Applications](https://arxiv.org/pdf/1812.08434.pdf)\n",
    "\n",
    "#### Objective\n",
    "\n",
    "This assignment will teach you how to use machine learning and molecular modeling, specifically Graph Neural Networks in combination with molecular docking, to select potent small molecule PD-1/PD-L1 inhibitors.\n",
    "\n",
    "#### Procedure\n",
    "\n",
    "#### Step 1a -  Downloading required files and scripts\n",
    "\n",
    "All the files and scripts required for the assignment can be downloaded from here. Make a sub directory in your working directory for this assignment. Make folders fullmodel/, input/, test/, train/ in this sub directory and copy all the scripts into the subdirectory. Now you should have four folders and downloaded scripts in your working directory. Now place the data.txt and test.txt files in the input/ directory. The data.txt file has SMILES, 96 CANDOCK docking scores against PD-L1 homodimer and their active or inactive status. The test.txt file also have SMILES and docking scores. Here, information in the data.txt file will be used to train the machine learning model and the trained machine learning model (EGNN) will be used to predict the activity of a molecular library in test.txt.\n",
    "\n",
    "Link to download EGNN Model\n",
    "http://chopra-modules.science.purdue.edu/class/chm579/spring2020/public/assignments/lab6_2020/lab6b/egnn-master.zip \n",
    "\n",
    "#### Step 1b - Creating a Python environment and install required packages\n",
    "\n",
    "**Don't run any commands for this in the Jupyter Notebook, you should run them in the VS Code terminal as it the bash kernel will not interface well with the Conda module on Scholar** \n",
    "\n",
    "Run commands below to create the python environment and install packages\n",
    "\n",
    "```\n",
    "module load anaconda\n",
    "rcac-conda-env create -n egnn -j\n",
    "source activate egnn\n",
    "conda install pytorch -c pytorch\n",
    "conda install -c rdkit rdkit\n",
    "conda install -c anaconda scikit-learn\n",
    "conda install pandas==1.5.3\n",
    "```\n",
    "\n",
    "#### Step 2 - Preprocessing data\n",
    "\n",
    "This step will preprocess the given data. It will open both `data.txt` and `test.txt` files and save the data separately as needed to run the training step. Here we can change the sub-graph radius with in the `preprocess_data.sh` script. It has been set to 2 by default. Following command can be used to do this.\n",
    "\n",
    "```\n",
    "bash preprocess_data.sh\n",
    "```\n",
    "\n",
    "If running the script is successful, you will see some prepared files in the train/ folder.\n",
    "\n",
    "#### Step 3 - Run training\n",
    "\n",
    "Open and see the parameters in the `run_training.sh` script. You should keep the same sub-graph radius which you used for pre-processing data. Keep the other parameters as defaults. You can use following command to start training the model.\n",
    "\n",
    "```\n",
    "bash run_training.sh\n",
    "```\n",
    "\n",
    "After training is finished you will see a model file and a text file in the fullmodel/ directory. The text file will have the epoch, time, training loss, validation loss, area under the curve (AUC), precision, recall and F1 score.\n",
    "\n",
    "#### Step 4 - Train full with bootstrapping and take predictions for the test set\n",
    "\n",
    "Use the following command to start training with bootstrapping. This will train the model hundred times with hundred different random seeds and record all the data in the bootstrapping_results directory. You should keep same parameters which you used in step 03.\n",
    "\n",
    "```\n",
    "sbatch train_full.sh\n",
    "```\n",
    "\n",
    "After training with bootstrapping is done, create a subdirectory called `bootstrapping_results/` in the working directory. Then use the following command to take predictions. Again keep same parameters.\n",
    "\n",
    "```\n",
    "bash run_test.sh\n",
    "```\n",
    "\n",
    "A csv file with all the predictions for the test set will be generated in the working directory. The take_counts.py script can be used to calculate the number of times a molecule to be predicted as active over number of bootstrapped models. Then this number can be combined with main results using the script `combining_smiles_bootstrapping_average_countsover0.5.py`. Sripts can be used as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "1. Change the dim (molecular vector dimension) parameter in the run_training.sh script and run it for 6 different numbers. (eg: You can try dim = 6, 7, 8, 9, 10, 15). Then plot average F1 score against epoch for these dim parameter values in the same plot.\n",
    "\n",
    "2. Generate similar plots for radius parameter (radius = 2 and 3 ) and hidden_layer parameter. Determine most suitable parameters to be used in the training of EGNN for this data based on the graphs which you have plotted.\n",
    "\n",
    "3. Calculate and report the average training F1 score, average validation F1 score, average training AUC and average validation AUC for the EGNN model over five folds.\n",
    "\n",
    "4. Give structures of the top five predictions you got as final results with their respective average softmax scores with the standard deviation.\n",
    "\n",
    "5. What is the effect of bootstrapping in EGNN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
